{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e424926-18ce-4db1-b9ee-d2cc43a8919f",
   "metadata": {},
   "source": [
    "### 딥러닝을 이용한 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f15550-7a9f-4202-b1e0-d37704632f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08894fe-66e5-463c-b0ae-78ee04ef2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공부시간과 성적에 대한 상관/회귀 분석\n",
    "x = [2,4,6,8]\n",
    "y = [81,93,91,97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93e1f27-2d9d-4e55-b82e-e69632aab779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 9.0, 75.0, 100.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.axis([1,9,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d497c0-2148-4b4b-bcf1-74cedb96a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로와 경사하강법을 이용한 선형회귀 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0697f557-833f-4e26-bfd5-8f5f715054ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y 데이터 설정\n",
    "data = [[2,81],[4,93],[6,91],[8,97]]    # 2차원 텐서 정의\n",
    "x_data = [x[0] for x in data]\n",
    "y_data = [x[1] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a2779d-6aa0-4cc4-9b8c-1d02c2651d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y 데이터 설정\n",
    "data = [[2,81],[4,93],[6,91],[8,97]]    # 2차원 텐서 정의\n",
    "x_data = [x[0] for x in data]\n",
    "y_data = [x[1] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6880b767-38be-4df8-aa8c-55eaed3237e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2236/99079234.py:4: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 기울기 a와 절편 b는 임의의 범위로 설정\n",
    "# 기울기는 0~10, 절편은 0~100으로 설정\n",
    "import tensorflow as tf\n",
    "a = tf.Variable(tf.random_uniform([1], 0, 10,\n",
    "                dtype=tf.float64, seed=1))\n",
    "b = tf.Variable(tf.random_uniform([1], 0, 100,\n",
    "                dtype=tf.float64, seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52bc921d-f13e-4f1a-9c0f-32afb68e810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀식 정의\n",
    "y = a * x_data + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67ddc1e-6b23-4f67-9f4c-3c764a0a6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로에서 제공하는 평균제곱근 함수 사용\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(y - y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "769df8fe-16e0-4e05-b539-5d49424a2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 정의\n",
    "learn_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07a0a89d-e3ac-40b4-b144-ec77e868211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2236/1170215251.py:2: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RMSE를 최소로 하는 값 찾기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer\\\n",
    "              (learn_rate).minimize(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55840735-c5de-462a-a048-e3f3dfb3fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련횟수 epoch 0, RMSE 45.830,기울기 8.579, 절편 91.135\n",
      "훈련횟수 epoch 10, RMSE 16.089,기울기 3.205, 절편 90.175\n",
      "훈련횟수 epoch 20, RMSE 5.157,기울기 0.550, 절편 89.476\n",
      "훈련횟수 epoch 30, RMSE 5.046,기울기 0.600, 절편 89.147\n",
      "훈련횟수 epoch 40, RMSE 4.938,기울기 0.654, 절편 88.822\n",
      "훈련횟수 epoch 50, RMSE 4.832,기울기 0.708, 절편 88.502\n",
      "훈련횟수 epoch 60, RMSE 4.729,기울기 0.761, 절편 88.185\n",
      "훈련횟수 epoch 70, RMSE 4.628,기울기 0.813, 절편 87.871\n",
      "훈련횟수 epoch 80, RMSE 4.530,기울기 0.865, 절편 87.563\n",
      "훈련횟수 epoch 90, RMSE 4.435,기울기 0.916, 절편 87.258\n",
      "훈련횟수 epoch 100, RMSE 4.343,기울기 0.966, 절편 86.958\n",
      "훈련횟수 epoch 110, RMSE 4.253,기울기 1.016, 절편 86.663\n",
      "훈련횟수 epoch 120, RMSE 4.167,기울기 1.064, 절편 86.374\n",
      "훈련횟수 epoch 130, RMSE 4.084,기울기 1.112, 절편 86.089\n",
      "훈련횟수 epoch 140, RMSE 4.004,기울기 1.159, 절편 85.810\n",
      "훈련횟수 epoch 150, RMSE 3.927,기울기 1.205, 절편 85.537\n",
      "훈련횟수 epoch 160, RMSE 3.854,기울기 1.249, 절편 85.270\n",
      "훈련횟수 epoch 170, RMSE 3.784,기울기 1.293, 절편 85.009\n",
      "훈련횟수 epoch 180, RMSE 3.717,기울기 1.336, 절편 84.754\n",
      "훈련횟수 epoch 190, RMSE 3.654,기울기 1.377, 절편 84.506\n",
      "훈련횟수 epoch 200, RMSE 3.595,기울기 1.418, 절편 84.265\n",
      "훈련횟수 epoch 210, RMSE 3.538,기울기 1.457, 절편 84.031\n",
      "훈련횟수 epoch 220, RMSE 3.485,기울기 1.495, 절편 83.803\n",
      "훈련횟수 epoch 230, RMSE 3.435,기울기 1.532, 절편 83.583\n",
      "훈련횟수 epoch 240, RMSE 3.389,기울기 1.568, 절편 83.370\n",
      "훈련횟수 epoch 250, RMSE 3.345,기울기 1.602, 절편 83.164\n",
      "훈련횟수 epoch 260, RMSE 3.305,기울기 1.635, 절편 82.966\n",
      "훈련횟수 epoch 270, RMSE 3.267,기울기 1.668, 절편 82.774\n",
      "훈련횟수 epoch 280, RMSE 3.232,기울기 1.698, 절편 82.590\n",
      "훈련횟수 epoch 290, RMSE 3.200,기울기 1.728, 절편 82.413\n",
      "훈련횟수 epoch 300, RMSE 3.171,기울기 1.756, 절편 82.244\n",
      "훈련횟수 epoch 310, RMSE 3.144,기울기 1.784, 절편 82.081\n",
      "훈련횟수 epoch 320, RMSE 3.119,기울기 1.810, 절편 81.925\n",
      "훈련횟수 epoch 330, RMSE 3.096,기울기 1.835, 절편 81.776\n",
      "훈련횟수 epoch 340, RMSE 3.075,기울기 1.859, 절편 81.634\n",
      "훈련횟수 epoch 350, RMSE 3.056,기울기 1.881, 절편 81.498\n",
      "훈련횟수 epoch 360, RMSE 3.039,기울기 1.903, 절편 81.368\n",
      "훈련횟수 epoch 370, RMSE 3.023,기울기 1.924, 절편 81.244\n",
      "훈련횟수 epoch 380, RMSE 3.009,기울기 1.944, 절편 81.127\n",
      "훈련횟수 epoch 390, RMSE 2.996,기울기 1.962, 절편 81.015\n",
      "훈련횟수 epoch 400, RMSE 2.984,기울기 1.980, 절편 80.908\n",
      "훈련횟수 epoch 410, RMSE 2.974,기울기 1.997, 절편 80.807\n",
      "훈련횟수 epoch 420, RMSE 2.964,기울기 2.013, 절편 80.710\n",
      "훈련횟수 epoch 430, RMSE 2.956,기울기 2.029, 절편 80.619\n",
      "훈련횟수 epoch 440, RMSE 2.948,기울기 2.043, 절편 80.532\n",
      "훈련횟수 epoch 450, RMSE 2.941,기울기 2.057, 절편 80.450\n",
      "훈련횟수 epoch 460, RMSE 2.935,기울기 2.070, 절편 80.372\n",
      "훈련횟수 epoch 470, RMSE 2.929,기울기 2.083, 절편 80.298\n",
      "훈련횟수 epoch 480, RMSE 2.924,기울기 2.094, 절편 80.228\n",
      "훈련횟수 epoch 490, RMSE 2.920,기울기 2.105, 절편 80.161\n",
      "훈련횟수 epoch 500, RMSE 2.916,기울기 2.116, 절편 80.098\n",
      "훈련횟수 epoch 510, RMSE 2.912,기울기 2.126, 절편 80.039\n",
      "훈련횟수 epoch 520, RMSE 2.909,기울기 2.135, 절편 79.982\n",
      "훈련횟수 epoch 530, RMSE 2.906,기울기 2.144, 절편 79.929\n",
      "훈련횟수 epoch 540, RMSE 2.903,기울기 2.153, 절편 79.878\n",
      "훈련횟수 epoch 550, RMSE 2.901,기울기 2.161, 절편 79.830\n",
      "훈련횟수 epoch 560, RMSE 2.899,기울기 2.168, 절편 79.785\n",
      "훈련횟수 epoch 570, RMSE 2.897,기울기 2.176, 절편 79.742\n",
      "훈련횟수 epoch 580, RMSE 2.895,기울기 2.182, 절편 79.702\n",
      "훈련횟수 epoch 590, RMSE 2.894,기울기 2.189, 절편 79.663\n",
      "훈련횟수 epoch 600, RMSE 2.892,기울기 2.195, 절편 79.627\n",
      "훈련횟수 epoch 610, RMSE 2.891,기울기 2.201, 절편 79.593\n",
      "훈련횟수 epoch 620, RMSE 2.890,기울기 2.206, 절편 79.560\n",
      "훈련횟수 epoch 630, RMSE 2.889,기울기 2.211, 절편 79.530\n",
      "훈련횟수 epoch 640, RMSE 2.888,기울기 2.216, 절편 79.501\n",
      "훈련횟수 epoch 650, RMSE 2.887,기울기 2.221, 절편 79.473\n",
      "훈련횟수 epoch 660, RMSE 2.887,기울기 2.225, 절편 79.447\n",
      "훈련횟수 epoch 670, RMSE 2.886,기울기 2.229, 절편 79.423\n",
      "훈련횟수 epoch 680, RMSE 2.886,기울기 2.233, 절편 79.400\n",
      "훈련횟수 epoch 690, RMSE 2.885,기울기 2.237, 절편 79.378\n",
      "훈련횟수 epoch 700, RMSE 2.885,기울기 2.240, 절편 79.357\n",
      "훈련횟수 epoch 710, RMSE 2.884,기울기 2.243, 절편 79.338\n",
      "훈련횟수 epoch 720, RMSE 2.884,기울기 2.247, 절편 79.319\n",
      "훈련횟수 epoch 730, RMSE 2.884,기울기 2.249, 절편 79.302\n",
      "훈련횟수 epoch 740, RMSE 2.883,기울기 2.252, 절편 79.285\n",
      "훈련횟수 epoch 750, RMSE 2.883,기울기 2.255, 절편 79.269\n",
      "훈련횟수 epoch 760, RMSE 2.883,기울기 2.257, 절편 79.255\n",
      "훈련횟수 epoch 770, RMSE 2.883,기울기 2.260, 절편 79.241\n",
      "훈련횟수 epoch 780, RMSE 2.882,기울기 2.262, 절편 79.227\n",
      "훈련횟수 epoch 790, RMSE 2.882,기울기 2.264, 절편 79.215\n",
      "훈련횟수 epoch 800, RMSE 2.882,기울기 2.266, 절편 79.203\n",
      "훈련횟수 epoch 810, RMSE 2.882,기울기 2.268, 절편 79.192\n",
      "훈련횟수 epoch 820, RMSE 2.882,기울기 2.270, 절편 79.182\n",
      "훈련횟수 epoch 830, RMSE 2.882,기울기 2.271, 절편 79.172\n",
      "훈련횟수 epoch 840, RMSE 2.882,기울기 2.273, 절편 79.162\n",
      "훈련횟수 epoch 850, RMSE 2.882,기울기 2.274, 절편 79.153\n",
      "훈련횟수 epoch 860, RMSE 2.882,기울기 2.276, 절편 79.145\n",
      "훈련횟수 epoch 870, RMSE 2.882,기울기 2.277, 절편 79.137\n",
      "훈련횟수 epoch 880, RMSE 2.881,기울기 2.278, 절편 79.129\n",
      "훈련횟수 epoch 890, RMSE 2.881,기울기 2.280, 절편 79.122\n",
      "훈련횟수 epoch 900, RMSE 2.881,기울기 2.281, 절편 79.116\n",
      "훈련횟수 epoch 910, RMSE 2.881,기울기 2.282, 절편 79.109\n",
      "훈련횟수 epoch 920, RMSE 2.881,기울기 2.283, 절편 79.103\n",
      "훈련횟수 epoch 930, RMSE 2.881,기울기 2.284, 절편 79.098\n",
      "훈련횟수 epoch 940, RMSE 2.881,기울기 2.285, 절편 79.092\n",
      "훈련횟수 epoch 950, RMSE 2.881,기울기 2.285, 절편 79.087\n",
      "훈련횟수 epoch 960, RMSE 2.881,기울기 2.286, 절편 79.082\n",
      "훈련횟수 epoch 970, RMSE 2.881,기울기 2.287, 절편 79.078\n",
      "훈련횟수 epoch 980, RMSE 2.881,기울기 2.288, 절편 79.074\n",
      "훈련횟수 epoch 990, RMSE 2.881,기울기 2.288, 절편 79.070\n",
      "훈련횟수 epoch 1000, RMSE 2.881,기울기 2.289, 절편 79.066\n",
      "훈련횟수 epoch 1010, RMSE 2.881,기울기 2.290, 절편 79.062\n",
      "훈련횟수 epoch 1020, RMSE 2.881,기울기 2.290, 절편 79.059\n",
      "훈련횟수 epoch 1030, RMSE 2.881,기울기 2.291, 절편 79.056\n",
      "훈련횟수 epoch 1040, RMSE 2.881,기울기 2.291, 절편 79.052\n",
      "훈련횟수 epoch 1050, RMSE 2.881,기울기 2.292, 절편 79.050\n",
      "훈련횟수 epoch 1060, RMSE 2.881,기울기 2.292, 절편 79.047\n",
      "훈련횟수 epoch 1070, RMSE 2.881,기울기 2.293, 절편 79.044\n",
      "훈련횟수 epoch 1080, RMSE 2.881,기울기 2.293, 절편 79.042\n",
      "훈련횟수 epoch 1090, RMSE 2.881,기울기 2.293, 절편 79.040\n",
      "훈련횟수 epoch 1100, RMSE 2.881,기울기 2.294, 절편 79.037\n",
      "훈련횟수 epoch 1110, RMSE 2.881,기울기 2.294, 절편 79.035\n",
      "훈련횟수 epoch 1120, RMSE 2.881,기울기 2.294, 절편 79.033\n",
      "훈련횟수 epoch 1130, RMSE 2.881,기울기 2.295, 절편 79.032\n",
      "훈련횟수 epoch 1140, RMSE 2.881,기울기 2.295, 절편 79.030\n",
      "훈련횟수 epoch 1150, RMSE 2.881,기울기 2.295, 절편 79.028\n",
      "훈련횟수 epoch 1160, RMSE 2.881,기울기 2.296, 절편 79.027\n",
      "훈련횟수 epoch 1170, RMSE 2.881,기울기 2.296, 절편 79.025\n",
      "훈련횟수 epoch 1180, RMSE 2.881,기울기 2.296, 절편 79.024\n",
      "훈련횟수 epoch 1190, RMSE 2.881,기울기 2.296, 절편 79.022\n",
      "훈련횟수 epoch 1200, RMSE 2.881,기울기 2.296, 절편 79.021\n",
      "훈련횟수 epoch 1210, RMSE 2.881,기울기 2.297, 절편 79.020\n",
      "훈련횟수 epoch 1220, RMSE 2.881,기울기 2.297, 절편 79.019\n",
      "훈련횟수 epoch 1230, RMSE 2.881,기울기 2.297, 절편 79.018\n",
      "훈련횟수 epoch 1240, RMSE 2.881,기울기 2.297, 절편 79.017\n",
      "훈련횟수 epoch 1250, RMSE 2.881,기울기 2.297, 절편 79.016\n",
      "훈련횟수 epoch 1260, RMSE 2.881,기울기 2.297, 절편 79.015\n",
      "훈련횟수 epoch 1270, RMSE 2.881,기울기 2.298, 절편 79.014\n",
      "훈련횟수 epoch 1280, RMSE 2.881,기울기 2.298, 절편 79.014\n",
      "훈련횟수 epoch 1290, RMSE 2.881,기울기 2.298, 절편 79.013\n",
      "훈련횟수 epoch 1300, RMSE 2.881,기울기 2.298, 절편 79.012\n",
      "훈련횟수 epoch 1310, RMSE 2.881,기울기 2.298, 절편 79.011\n",
      "훈련횟수 epoch 1320, RMSE 2.881,기울기 2.298, 절편 79.011\n",
      "훈련횟수 epoch 1330, RMSE 2.881,기울기 2.298, 절편 79.010\n",
      "훈련횟수 epoch 1340, RMSE 2.881,기울기 2.298, 절편 79.010\n",
      "훈련횟수 epoch 1350, RMSE 2.881,기울기 2.298, 절편 79.009\n",
      "훈련횟수 epoch 1360, RMSE 2.881,기울기 2.299, 절편 79.009\n",
      "훈련횟수 epoch 1370, RMSE 2.881,기울기 2.299, 절편 79.008\n",
      "훈련횟수 epoch 1380, RMSE 2.881,기울기 2.299, 절편 79.008\n",
      "훈련횟수 epoch 1390, RMSE 2.881,기울기 2.299, 절편 79.007\n",
      "훈련횟수 epoch 1400, RMSE 2.881,기울기 2.299, 절편 79.007\n",
      "훈련횟수 epoch 1410, RMSE 2.881,기울기 2.299, 절편 79.006\n",
      "훈련횟수 epoch 1420, RMSE 2.881,기울기 2.299, 절편 79.006\n",
      "훈련횟수 epoch 1430, RMSE 2.881,기울기 2.299, 절편 79.006\n",
      "훈련횟수 epoch 1440, RMSE 2.881,기울기 2.299, 절편 79.005\n",
      "훈련횟수 epoch 1450, RMSE 2.881,기울기 2.299, 절편 79.005\n",
      "훈련횟수 epoch 1460, RMSE 2.881,기울기 2.299, 절편 79.005\n",
      "훈련횟수 epoch 1470, RMSE 2.881,기울기 2.299, 절편 79.005\n",
      "훈련횟수 epoch 1480, RMSE 2.881,기울기 2.299, 절편 79.004\n",
      "훈련횟수 epoch 1490, RMSE 2.881,기울기 2.299, 절편 79.004\n",
      "훈련횟수 epoch 1500, RMSE 2.881,기울기 2.299, 절편 79.004\n",
      "훈련횟수 epoch 1510, RMSE 2.881,기울기 2.299, 절편 79.004\n",
      "훈련횟수 epoch 1520, RMSE 2.881,기울기 2.299, 절편 79.003\n",
      "훈련횟수 epoch 1530, RMSE 2.881,기울기 2.299, 절편 79.003\n",
      "훈련횟수 epoch 1540, RMSE 2.881,기울기 2.299, 절편 79.003\n",
      "훈련횟수 epoch 1550, RMSE 2.881,기울기 2.300, 절편 79.003\n",
      "훈련횟수 epoch 1560, RMSE 2.881,기울기 2.300, 절편 79.003\n",
      "훈련횟수 epoch 1570, RMSE 2.881,기울기 2.300, 절편 79.003\n",
      "훈련횟수 epoch 1580, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1590, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1600, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1610, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1620, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1630, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1640, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1650, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1660, RMSE 2.881,기울기 2.300, 절편 79.002\n",
      "훈련횟수 epoch 1670, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1680, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1690, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1700, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1710, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1720, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1730, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1740, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1750, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1760, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1770, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1780, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1790, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1800, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1810, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1820, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1830, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1840, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1850, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1860, RMSE 2.881,기울기 2.300, 절편 79.001\n",
      "훈련횟수 epoch 1870, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1880, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1890, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1900, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1910, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1920, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1930, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1940, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1950, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1960, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1970, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1980, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 1990, RMSE 2.881,기울기 2.300, 절편 79.000\n",
      "훈련횟수 epoch 2000, RMSE 2.881,기울기 2.300, 절편 79.000\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로로 학습 시도\n",
    "with tf.Session() as sess:\n",
    "    # 텐서플로 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 학습횟수만큼 훈련 - 적절한 기울기 찾음\n",
    "    # 총 학습횟수는 2000, 10회때마다 진행상황 출력\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_decent)\n",
    "        if step % 10 == 0:\n",
    "            print('훈련횟수 epoch %.f, RMSE %.3f,'\\\n",
    "            '기울기 %.3f, 절편 %.3f' %\n",
    "                  ( step, sess.run(rmse),\n",
    "                    sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd2f53-04df-420f-a90b-9b0dca424e91",
   "metadata": {},
   "source": [
    "### 경사하강법 적용시 고려사항\n",
    "* 학습률 : 기울기의 부호를 바뀌 이동시킬때 적절한 거리를 찾지 못해 너무 멀리 이동시키면 중심점을 지나칠수도 있음\n",
    "* 따라서, 어느 만큼 이동시킬지 신중히 결정해야 함\n",
    "* 케라스는 자동으로 이동거리를 조절해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "679bad4d-7fd9-408b-9c50-bd09297e204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f73e6a4-ee2c-4abd-94d7-fbdc82230069",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = [2,4,6,8]\n",
    "ytrain = [81,93,91,97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bfbe84c-11d2-4560-bd3e-cc12e6700e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hadoop/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69f0a779-1b87-40b1-b017-f02970080534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용계산 함수 : rmse\n",
    "model.compile(loss='mse', optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffacbe23-a412-4fb8-8d62-42b4cc7ca214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f07ef5425d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2500회의 학습 시행, 진행상황 표시 - 1 출력 0 미출력\n",
    "model.fit(xtrain, ytrain, epochs=2500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a31eda43-9a8e-4325-8936-63cf0ea55763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기 2.300\n",
      "절편 78.999\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print('기울기 %.3f' % model.get_weights()[0])\n",
    "print('절편 %.3f' % model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7a88ec3-163e-4776-bf9f-13b4d6eb1022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55시간 공부하면 성적은 [[205.50935]]\n",
      "10시간 공부하면 성적은 [[102.00076]]\n"
     ]
    }
   ],
   "source": [
    "# 예측하기\n",
    "ypredict = model.predict(np.array([55]))\n",
    "print('55시간 공부하면 성적은', ypredict)\n",
    "\n",
    "ypredict = model.predict(np.array([10]))\n",
    "print('10시간 공부하면 성적은', ypredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e033a5-849b-4b22-94c5-4686f5abbc3a",
   "metadata": {},
   "source": [
    "* 손실함수loss function\n",
    "     + 비용cost함수라고도 함\n",
    "     + 신경망이 잘 학습하고 있는지를 나타내주는 지표\n",
    "    + 손실loss,비용cost은 출력값과 실제값 사이의 오차를 의미\n",
    "     + 신경망에서는 이것들이 최소화되도록 하는 과정이 학습임\n",
    "     + 따라서, 손실이 최소화된다는 것은 학습이 잘되고 있음을 의미<br><br>\n",
    "\n",
    "* 딥러닝에서 손실함수는 평균제곱오차MSE(회귀)와 교차엔트로피오차CEE(분류)를 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3996f-98ea-4bc8-98d2-feda39a1911d",
   "metadata": {},
   "source": [
    "* 학습 최적화 방법\n",
    "* 텐서플로에서는 optimizer로 설정\n",
    "\n",
    "* 경사하강법SGD - 확률적 경사하강법 : 무작위 값을 대입\n",
    "\n",
    "* 모멘텀        - SGD + 무작위값에 탄성을 부여 (정확도 개선)\n",
    "\n",
    "* 아다그라드adagrad - 학습률에 탄성을 부여 (보폭크기 개선)\n",
    "*                     무작위값 대입 횟수를 조절\n",
    "\n",
    "* RMSprop - adagrad의 보폭 민감도를 개선 (보폭크기 개선)\n",
    "\n",
    "* Adam - 무작위값에 탄성부여, 학습률에도 탄성 부여\n",
    "    + 즉, 정확도 개선 + 보폭크기 개선\n",
    "    + keras.optimizer.Adam(lr=0.0001,\n",
    "    + beta_1=0.9, beta_2=0.9999,\n",
    "    + elpsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b01aef-a746-42df-b9b6-20ef177a45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
